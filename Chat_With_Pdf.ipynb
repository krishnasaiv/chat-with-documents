{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "cell_execution_strategy": "setup",
      "authorship_tag": "ABX9TyOoV3LItE7iKWp7T913z7MY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/krishnasaiv/chat-with-your-documents/blob/main/Chat_With_Pdf.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Steps\n",
        "\n",
        "\n",
        "1.   Read pdf file (singular first)\n",
        "2.   Chunk it\n",
        "3.   Extract Embeddings ([Instruct Embeddings](https://huggingface.co/hkunlp/instructor-xl) )\n",
        "4.   Build an embedding index & store them in a vector database (Faiss)\n",
        "5.   Perform Vector search with Queries & extract most relevant chunks\n",
        "6.   Use the searched chunks as inputs to LLM and answer the query  ([Facebook LLaMa2](https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard))"
      ],
      "metadata": {
        "id": "sLXcDlPmOQzS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install transformers==4.20.0\n",
        "! pip install datasets>=2.2.0\n",
        "! pip install jsonlines\n",
        "! pip install numpy\n",
        "! pip install requests>=2.26.0\n",
        "! pip install scikit_learn>=1.0.2\n",
        "! pip install scipy\n",
        "! pip install sentence_transformers>=2.2.0\n",
        "! pip install torch\n",
        "! pip install tqdm\n",
        "! pip install rich\n",
        "! pip install Cython\n",
        "\n",
        "! pip install langchain==0.0.184\n",
        "! pip install PyPDF2==3.0.1\n",
        "\n",
        "# python-dotenv==1.0.0\n",
        "# streamlit==1.18.1\n",
        "# openai==0.27.6\n",
        "\n",
        "! pip install faiss-cpu==1.7.4\n",
        "! pip install altair==4\n",
        "! pip install tiktoken==0.4.0\n",
        "\n",
        "\n",
        "! pip install huggingface-hub==0.14.1\n",
        "\n",
        "! pip install InstructorEmbedding==1.0.1\n",
        "# ! pip install sentence-transformers==2.2.2"
      ],
      "metadata": {
        "id": "HZAUggROkUZ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ! pip install PyPDF2 langchain InstructorEmbedding torch\n",
        "\n",
        "from PyPDF2 import PdfReader\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain.embeddings import OpenAIEmbeddings, HuggingFaceInstructEmbeddings\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "from langchain.chains import ConversationalRetrievalChain\n",
        "\n",
        "from langchain.chains.question_answering import load_qa_chain\n",
        "\n",
        "# from htmlTemplates import css, bot_template, user_template\n",
        "from langchain.llms import HuggingFaceHub"
      ],
      "metadata": {
        "id": "ejDT6yGG1DWL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Read Pdf Files\n",
        "\n",
        "\n",
        "**Upload your Pdf Files before running**"
      ],
      "metadata": {
        "id": "j7_E-1bRQIOm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "filename = \"./HP1 - Harry Potter and the Sorcerer's Stone.pdf\"\n",
        "\n",
        "doc = PdfReader(filename)\n",
        "text = \"\"\n",
        "for page in doc.pages:\n",
        "    text += page.extract_text()\n",
        "\n",
        "len(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Pwyb8eqxLGr",
        "outputId": "7c00b958-7d1b-41c7-c4af-68a826eadc38"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "462945"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Chunk it"
      ],
      "metadata": {
        "id": "q7NA-IH-0sB9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# qtr_len = len(text)//4\n",
        "# short_text = text[:qtr_len]\n",
        "# len(short_text)\n",
        "# qtr_len"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d3XKWJFHwxzq",
        "outputId": "a6ef9763-8900-4209-9fff-2f8fbaf20963"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "115736"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "abb60fb3-6b3a-4126-bd3c-25d0b610387c",
        "id": "M-dPDS4Z0sCB"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1031"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "text_splitter = CharacterTextSplitter(\n",
        "        separator=\"\\n\",\n",
        "        chunk_size=650,\n",
        "        chunk_overlap=200,\n",
        "        length_function=len\n",
        ")\n",
        "chunks = text_splitter.split_text(text)\n",
        "len(chunks)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create Embeddings &\n",
        "### Build an embedding index & store them in a vector database (Faiss)"
      ],
      "metadata": {
        "id": "7rBhEC5o1csS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "embeddings = HuggingFaceInstructEmbeddings(model_name=\"hkunlp/instructor-xl\", )\n",
        "knowledge_base = FAISS.from_texts(texts=chunks, embedding=embeddings)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CQpMWN0ARok6",
        "outputId": "6bb87ebd-f29e-4c10-e83e-7606159ef9b0"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/InstructorEmbedding/instructor.py:7: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
            "  from tqdm.autonotebook import trange\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "load INSTRUCTOR_Transformer\n",
            "max_seq_length  512\n",
            "CPU times: user 3min 22s, sys: 10.2 s, total: 3min 32s\n",
            "Wall time: 3min 55s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load Google Flan T5 LLm\n",
        "\n",
        "-- Facebook LLaMa2"
      ],
      "metadata": {
        "id": "AKpXHaSHmzdb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ['HUGGINGFACEHUB_API_TOKEN'] = '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'\n",
        "\n",
        "llm = HuggingFaceHub(\n",
        "    repo_id=\"google/flan-t5-xxl\"\n",
        "    , model_kwargs={\"temperature\":0.1}\n",
        ")\n",
        "\n",
        "conversation_chain = load_qa_chain(\n",
        "    llm\n",
        "    , chain_type=\"stuff\"\n",
        ")\n",
        "\n",
        "# memory = ConversationBufferMemory(\n",
        "#     memory_key='chat_history'\n",
        "#     , return_messages=True\n",
        "# )\n",
        "\n",
        "# ConversationalRetrievalChain.from_llm(\n",
        "#     llm=llm\n",
        "#     , retriever=vectorstore.as_retriever()\n",
        "#     , memory=memory\n",
        "# )\n",
        "\n"
      ],
      "metadata": {
        "id": "swkgI4wVm6hP"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Perform Vector search with Queries & extract most relevant chunks"
      ],
      "metadata": {
        "id": "bhi2VO85mySo"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0WVAwOPF7K7x"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nV6V61117Lxt"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eouN0bsV7Lu2"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = input()\n",
        "\n",
        "docs = knowledge_base.similarity_search(query)\n",
        "# print(\"Num Relevant Docs: \", len(docs))\n",
        "# for i, doc in enumerate(docs[:5]):\n",
        "#     print(f\"{i + 1}.\", doc.page_content[:200], \"\\n\")\n",
        "\n",
        "\n",
        "response = conversation_chain.run(input_documents=docs, question=query)\n",
        "response"
      ],
      "metadata": {
        "id": "DFRjefsFuTPD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7aLvWAM2mqFb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fCw4WjwsmA5m"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}